{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPrYPwtfpMJFM+xEp+il/wk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"9rEvMJqNFAM3","executionInfo":{"status":"ok","timestamp":1677149285524,"user_tz":-60,"elapsed":9924,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["## Linear Layer -- Dimensionsreduktion/-erhöhung\n","$$y = f(x \\cdot W)$$"],"metadata":{"id":"45tERmStEY42"}},{"cell_type":"code","source":["# Modellinputs\n","BATCH_SIZE = 2\n","NUM_INPUTS = 10\n","INPUT_DIM = 3\n","x = tf.random.normal(shape=(BATCH_SIZE, NUM_INPUTS, INPUT_DIM))\n","print(\"Dimension des Inputs:\", x.shape)\n","\n","# Unser einfaches Modell mit 1 Linear Layer\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(units=5)\n","])\n","model.build(input_shape=x.shape)\n","print(\"Matrixdimension des Linear Layers:\", model.layers[0].weights[0].shape)\n","\n","# Der Linear Layer wird immer auf die letzte Dimension (3. Dim) angewendet \n","# Der Linear Layer kann parallel für alle Inputs (2. Dim) berechnet werden\n","y = model(x)\n","print(\"Dimension des Outputs:\", y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1pE2nIlYEweI","executionInfo":{"status":"ok","timestamp":1677149419049,"user_tz":-60,"elapsed":662,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}},"outputId":"0389f44b-2c7e-4dd6-a736-2d0e2a309e4c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimension des Inputs: (2, 10, 3)\n","Matrixdimension des Linear Layers: (3, 5)\n","Dimension des Outputs: (2, 10, 5)\n"]}]},{"cell_type":"markdown","source":["## Recurrent Layer -- Informationen aus dem vorigen Zeitschritt verwenden\n","$$s_t = f(s_{t-1} \\cdot R + x_t \\cdot W)$$"],"metadata":{"id":"m1N0Sw2YEw7g"}},{"cell_type":"code","source":["# wir benutzen \"x\" aus dem vorigen Beispiel\n","print(\"Dimension des Inputs:\", x.shape)\n","\n","# Unser einfaches Modell mit 1 Linear Layer\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.SimpleRNN(units=5, return_sequences=True)\n","])\n","model.build(input_shape=x.shape)\n","\n","# Ein RNN hat einen Linear Layer, um die Input Dimension (hier 3) zu erhöhen (hier 5).\n","# Der rekurrente Kernel (hier 5x5 Matrix) wird danach angewendet.\n","# Die Inputs (2. Dim) ist die Zeitdimension t einer Sequenz/Zeitreihe.\n","y = model(x)\n","print(\"Dimension des Outputs:\", y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FD_Coo0IEzlk","executionInfo":{"status":"ok","timestamp":1677149648172,"user_tz":-60,"elapsed":1203,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}},"outputId":"3fe65b4b-b4c1-4c85-a2c3-1b0f9afe4de1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimension des Inputs: (2, 10, 3)\n","Dimension des Outputs: (2, 10, 5)\n"]}]},{"cell_type":"markdown","source":["## Convolution Layer -- Aggregiere benachbarte Inputs"],"metadata":{"id":"lls_SZCfE1os"}},{"cell_type":"code","source":["# wir benutzen \"x\" aus dem vorigen Beispiel\n","print(\"Dimension des Inputs:\", x.shape)\n","\n","# Unser einfaches Modell mit 1 Linear Layer\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Conv1D(filters=1, kernel_size=2)\n","])\n","model.build(input_shape=x.shape)\n","\n","# Der \"Kernel\" gleitet hier über \"kernel_size=2\" benachbarte Inputs und aggregiert diese.\n","y = model(x)\n","print(\"Dimension des Outputs:\", y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"piscUf0qG8KR","executionInfo":{"status":"ok","timestamp":1677149657083,"user_tz":-60,"elapsed":371,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}},"outputId":"439742f1-c48a-40d4-ad9a-dc0cce3d8df2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimension des Inputs: (2, 10, 3)\n","Dimension des Outputs: (2, 9, 1)\n"]}]},{"cell_type":"code","source":["# Die trainierbaren \"Filter\"-Gewichte\n","model.layers[0].weights[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6bpjsDoI7Fn","executionInfo":{"status":"ok","timestamp":1677106674755,"user_tz":-60,"elapsed":18,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}},"outputId":"7f1fdbbc-caa8-469b-b3c5-8ccfa76ffe33"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'conv1d_14/kernel:0' shape=(2, 3, 1) dtype=float32, numpy=\n","array([[[-0.5877724 ],\n","        [ 0.37192458],\n","        [ 0.01260459]],\n","\n","       [[ 0.1083079 ],\n","        [ 0.5347014 ],\n","        [-0.2614751 ]]], dtype=float32)>"]},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["## Attention Mechanism"],"metadata":{"id":"BYizYw4IE39L"}},{"cell_type":"code","source":["# wir benutzen \"x\" aus dem vorigen Beispiel\n","print(\"Dimension des Inputs:\", x.shape)\n","\n","dim = 5.\n","\n","# Projektionslayer (Wir benutzen hier die Keras Functional API)\n","Q = tf.keras.layers.Dense(units=dim)(x)\n","K = tf.keras.layers.Dense(units=dim)(x)\n","V = tf.keras.layers.Dense(units=dim)(x)\n","\n","# Die \"Energy\" weights W=Q*K.T\n","W = tf.einsum('bij,bkj->bik', Q, K)\n","# W = tf.einsum('bij,bkj->bik', x, x)\n","print(\"Energy:\", W.shape)\n","\n","# Attention Matrix\n","scaler = 1. / tf.sqrt(dim)\n","A = tf.nn.softmax(W * scaler, axis=2)\n","print(\"Attention:\", A.shape)\n","\n","# Multipliziere mit V\n","Y = tf.einsum('bij,bjk->bik', A, V)\n","print(\"Dimension des Outputs:\", Y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2Ci2FOpE7Kr","executionInfo":{"status":"ok","timestamp":1677150057472,"user_tz":-60,"elapsed":449,"user":{"displayName":"Ulf Hamster","userId":"17569698098126794188"}},"outputId":"aaa9d5a4-05b2-4037-b691-0b806a3c069c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimension des Inputs: (2, 10, 3)\n","Energy: (2, 10, 10)\n","Attention: (2, 10, 10)\n","Dimension des Outputs: (2, 10, 5)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mMyXr7mT7a_o"},"execution_count":null,"outputs":[]}]}